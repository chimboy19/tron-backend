
# # backend/utils/ocr_utils.py
# import tempfile
# import base64
# import os
# import re
# import logging
# from pdf2image import convert_from_bytes
# from config import Config
# from openai import OpenAI
# from difflib import get_close_matches
# import csv 


# client = OpenAI(api_key=Config.OPENAI_API_KEY) if Config.OPENAI_API_KEY else None

# log = logging.getLogger(__name__)

# def normalize_text(text: str) -> str:
#     if not text:
#         return ""
    
#     text = re.sub(r'[ï¼-ï¼™]', lambda m: str(ord(m.group()) - 0xFEE0), text)
#     return re.sub(r'\s+', ' ', text.strip())

# def extract_items_from_text(text: str):
#     """Extract items (H-codes and quantities) from text."""
#     if not text:
#         return []
#     text = normalize_text(text)
#     items = []
    
#     hcod_pattern = re.compile(
#         r'H\s*(\d{6})\s*(?:[:ï¼š\-\s]*[xÃ—*]?\s*(?:qty|æ•°é‡|å€‹|pcs|pc|ea|æœ¬|æš|ã‚»ãƒƒãƒˆ|units?)?\s*[:ï¼š]?\s*)?(\d+)',
#         re.IGNORECASE
#     )
#     for m in hcod_pattern.finditer(text):
#         code = f"H{m.group(1)}"
#         qty = int(m.group(2))
#         items.append((code, qty))

#     all_hcods = re.findall(r'H\s*(\d{6})', text, re.IGNORECASE)
#     existing = {code for code, _ in items}
#     for digits in all_hcods:
#         code = f"H{digits}"
#         if code not in existing:
#             items.append((code, 1))

    
#     lines = re.split(r'[\n\r]+', text)
#     for line in lines:
#         line = line.strip()
#         if not line:
#             continue
#         part_qty = re.search(
#             r'([\w\s\-â€“â€•/ï¼\(\)\[\]\u3000-\u9FFFÎ©Î¼a-zA-Z0-9\.\+\=\&]{2,80}?)'
#             r'\s*[xÃ—ï¼Š*]\s*'
#             r'(\d{1,5})'
#             r'(?:\s*(?:pcs|å€‹|æœ¬|æš|ã‚»ãƒƒãƒˆ|pc|ea|units?|ç‚¹))?\b',
#             line,
#             re.IGNORECASE
#         )
#         if part_qty:
#             name = part_qty.group(1).strip()
#             qty = int(part_qty.group(2))
#             name = re.sub(r'[,\.\-_:\s;ã€ã€‚]+$', '', name)
#             if len(name) >= 2:
#                 items.append((name, qty))
#             continue

#         fallback = re.search(
#             r'([\w\s\-â€“â€•/ï¼\(\)\[\]\u3000-\u9FFFÎ©Î¼a-zA-Z0-9\.\+\=\&]{2,80}?)\s+(\d{1,4})\s*$',
#             line,
#             re.IGNORECASE
#         )
#         if fallback:
#             name = fallback.group(1).strip()
#             qty = int(fallback.group(2))
#             name = re.sub(r'[,\.\-_:\s;ã€ã€‚]+$', '', name)
#             if len(name) >= 2:
#                 items.append((name, qty))
#     return items



# def ocr_pdf_with_openai(pdf_bytes: bytes) -> str:
#     """OCR a PDF using OpenAI Vision API with Japanese text support."""
#     if not client:
#         log.warning("OpenAI client not configured; skipping OCR.")
#         return ""
    
#     try:
        
#         log.info("ğŸ”„ Converting PDF to image for OCR...")
#         images = convert_from_bytes(pdf_bytes, first_page=1, last_page=3)  
#         if not images:
#             log.warning("No images could be extracted from PDF")
#             return ""
        
#         all_ocr_text = ""
        
#         for page_num, image in enumerate(images, 1):
#             log.info(f"ğŸ” Processing page {page_num} for OCR...")
            
           
#             img_path = os.path.join(tempfile.gettempdir(), f"temp_ocr_page_{page_num}.jpg")
#             image.save(img_path, format="JPEG", quality=85)
            
#             try:
#                 with open(img_path, "rb") as f:
#                     encoded_img = base64.b64encode(f.read()).decode('utf-8')
            
#                 image_data_url = f"data:image/jpeg;base64,{encoded_img}"
                
#                 prompt = """
#                      make sure to avoid duplicates


#                     ä»¥ä¸‹ã®æ³¨æ–‡æ›¸ç”»åƒã‹ã‚‰ã€æœ‰åŠ¹ãªã€Œéƒ¨å“è­˜åˆ¥å­ã€ã¨ã€Œæ•°é‡ã€ã®ã¿ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚\n"
#                     "\n"
#                     "ã€æœ‰åŠ¹ãªéƒ¨å“è­˜åˆ¥å­ã¨ã¯ã€‘\n"
#                     "- ãƒ¡ãƒ¼ã‚«å“ç•ªï¼ˆä¾‹: RK73Z1ETTP, CF1/4CS100J, MF1/2CC1003F, NV73DL1JTTE47ï¼‰\n"
#                     "- Hã‚³ãƒ¼ãƒ‰ï¼ˆä¾‹: H123456ï¼‰\n"
#                     "- å“ç•ªã¯è‹±æ•°å­—ã¨è¨˜å·ï¼ˆ/, -, .ï¼‰ã‚’å«ã¿ã€é€šå¸¸5æ–‡å­—ä»¥ä¸Š\n"
#                     "\n"
#                     "ã€çµ¶å¯¾ã«æŠ½å‡ºã—ãªã„ã‚‚ã®ã€‘\n"
#                     "- å†…éƒ¨ç®¡ç†ã‚³ãƒ¼ãƒ‰ï¼ˆä¾‹: EC00384035, 9KJ11105000, TD0-14524001, TE0-06366001ï¼‰\n"
#                     "- æ—¥æœ¬èªå“åã®ã¿ï¼ˆä¾‹: æŠµæŠ—å™¨ï¼‰\n"
#                     "- é‡‘é¡ã€ç´æœŸã€ç¨åŒºåˆ†ã€å‚™è€ƒã€ãƒ˜ãƒƒãƒ€ã€ãƒ•ãƒƒã‚¿ã€åˆè¨ˆè¡Œ\n"
#                     "\n"
#                     "ã€æ•°é‡ãƒ«ãƒ¼ãƒ«ã€‘\n"
#                     "- æ•°é‡ã¯å¯¾å¿œã™ã‚‹ã€Œæ•°é‡ã€æ¬„ã®æ•°å€¤ï¼ˆä¾‹: 100, 20000ï¼‰\n"
#                     "- ä¸æ˜ãªå ´åˆã¯ã€Œ1ã€\n"
#                     "\n"
#                     "ã€å‡ºåŠ›å½¢å¼ã€‘\n"
#                     "- 1è¡Œã«ã¤ãã€Œéƒ¨å“è­˜åˆ¥å­,æ•°é‡ã€ï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šï¼‰\n"
#                     "- ä¾‹:\n"
#                     "  RK73Z1ETTP,100\n"
#                     "  H123456,5\n"
#                     "  CF1/4CS100J,20000\n"
#                     "- èª¬æ˜æ–‡ã€ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã€ç©ºç™½è¡Œã€å¼•ç”¨ç¬¦ã¯å«ã‚ãªã„\n"
#                     "- ç´”ç²‹ãªãƒ†ã‚­ã‚¹ãƒˆã®ã¿å‡ºåŠ›

#                 """
                
#                 response = client.chat.completions.create(
#                     model="gpt-4o-mini",
#                     messages=[{
#                         "role": "user",
#                         "content": [
#                             {"type": "text", "text": prompt},
#                             {"type": "image_url", "image_url": {"url": image_data_url}}
#                         ]
#                     }],
#                     max_tokens=1500,
#                     temperature=0.1
#                 )
                
#                 page_text = getattr(response.choices[0].message, 'content', "") or ""
#                 if page_text:
#                     all_ocr_text += page_text + "\n"
#                     log.info(f"âœ… Page {page_num} OCR completed: {len(page_text)} characters")
#                     log.info(f"ğŸ“„ OCR text sample: {page_text[:200]}...")
                
#             except Exception as page_error:
#                 log.error(f"âŒ Error processing page {page_num}: {page_error}", exc_info=True)
#             finally:

#                 try:
#                     os.remove(img_path)
#                 except Exception:
#                     pass
        
#         log.info(f"ğŸ“„ OCR completed for {len(images)} pages, total text: {len(all_ocr_text)} characters")
#         return all_ocr_text.strip()
        
#     except Exception as e:
#         log.error(f"âŒ OCR error: {e}", exc_info=True)
#         return ""





# def extract_items_from_attachment(file_path):
    
#     if not isinstance(file_path, str) or not os.path.isfile(file_path):
#         log.warning("Invalid file path provided to extract_items_from_attachment")
#         return []

#     items = []
#     filename = os.path.basename(file_path)
#     log.info(f"ğŸ“ Processing attachment: {filename}")

#     try:
       
#         if filename.lower().endswith('.pdf'):
#             log.info(f"ğŸ“„ Processing Japanese PDF attachment: {filename}")
#             with open(file_path, 'rb') as f:
#                 pdf_bytes = f.read()
#             ocr_text = ocr_pdf_with_openai(pdf_bytes)
#             if not ocr_text:
#                 log.warning(" No text extracted from PDF via OCR")
#                 return items
#             log.info(f" OCR extracted {len(ocr_text)} characters")
#             log.info(f" Full OCR text:\n{ocr_text}")
#             for line in ocr_text.splitlines():
#                 line = line.strip()
#                 if not line:
#                     continue
#                 log.debug(f"ğŸ“„ OCR line: {line}")
#                 patterns = [
#                     r'^["\']?([^,\n]+?)["\']?\s*[,ï¼Œ]\s*(\d+)',
#                     r'^([^\s,]+)\s+(\d+)(?:\s*[å€‹æœ¬æšã‚»ãƒƒãƒˆ])?',
#                     r'^([^\sÃ—*]+)\s*[Ã—*]\s*(\d+)',
#                     r'^([^\s]+)\s+(\d+)\s*[å€‹æœ¬æš]',
#                     r'^(H\d{6})\s*[:ï¼š]?\s*(\d+)',
#                     r'^([A-Z0-9\u3000-\u9FFF\-_]+)\s+(\d+)\s*[^\d\s]*$',
#                 ]
#                 part_num = None
#                 qty = 1
#                 for pattern in patterns:
#                     m = re.match(pattern, line, re.IGNORECASE)
#                     if m:
#                         part_num = m.group(1).strip()
#                         try:
#                             qty = int(m.group(2))
#                         except (ValueError, TypeError):
#                             qty = 1
#                         log.info(f"ğŸ“¦ Pattern matched: {part_num} x {qty}")
#                         break
#                 if not part_num:
#                     h_match = re.search(r'(H\s*\d{6})', line, re.IGNORECASE)
#                     if h_match:
#                         part_num = h_match.group(1).replace(" ", "").upper()
#                         qty_match = re.search(r'H\s*\d{6}\s*[Ã—*]?\s*(\d+)', line, re.IGNORECASE)
#                         if qty_match:
#                             try:
#                                 qty = int(qty_match.group(1))
#                             except:
#                                 qty = 1
#                     else:
#                         tokens = re.findall(r'[A-Z0-9\u3000-\u9FFF\-_]{2,}', line)
#                         if tokens:
#                             part_num = tokens[0]
#                             qty_match = re.search(r'(\d+)\s*[å€‹æœ¬æš]?', line)
#                             if qty_match:
#                                 try:
#                                     qty = int(qty_match.group(1))
#                                 except:
#                                     qty = 1
#                 if part_num:
#                     part_num = part_num.strip().replace(" ", "").upper()
#                     part_num = re.sub(r'[\(ï¼ˆ].*[\)ï¼‰]', '', part_num)
#                     part_num = part_num.strip()
#                     if len(part_num) >= 2:
#                         items.append((part_num, qty))
#                         log.info(f"ğŸ“¦ Final extracted: {part_num} x {qty}")

#         # --- CSV PROCESSING ---

#         elif filename.lower().endswith('.csv'):
#             log.info(f"ğŸ“Š Processing CSV attachment: {filename}")
#             with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
#                 sample = f.read(2048)
#                 f.seek(0)
#                 try:
#                     delimiter = csv.Sniffer().sniff(sample).delimiter
#                 except Exception:
#                     delimiter = ','
#                 reader = csv.DictReader(f, delimiter=delimiter)
#                 for row in reader:
#                     row_lower = {(k or "").strip().lower(): (v or "").strip() for k, v in row.items() if k is not None}
#                     qty_val = (row_lower.get('qty') or row_lower.get('quantity') or 
#                               row_lower.get('æ•°é‡') or row_lower.get('å€‹æ•°') or 
#                               row_lower.get('q') or '1')
#                     try:
#                         qty = int(float(qty_val))
#                     except:
#                         qty = 1
#                     part_val = (row_lower.get('hcod') or row_lower.get('å“ç•ª') or 
#                                row_lower.get('hnm') or row_lower.get('part number') or 
#                                row_lower.get('mpn') or row_lower.get('å“å') or None)
#                     if part_val and str(part_val).strip():
#                         clean_part = str(part_val).strip().strip('"').strip("'")
#                         items.append((clean_part, qty))
#                         log.info(f"ğŸ“¦ CSV found: {clean_part} x {qty}")
#                     else:
#                         for k, v in row_lower.items():
#                             if k in ['qty', 'quantity', 'æ•°é‡', 'å€‹æ•°', 'q', '']:
#                                 continue
#                             if v and v.strip():
#                                 clean_part = v.strip().strip('"').strip("'")
#                                 items.append((clean_part, qty))
#                                 log.info(f"ğŸ“¦ CSV found (from column {k}): {clean_part} x {qty}")
#                                 break

#         # --- TEXT FILE PROCESSING ---
#         elif filename.lower().endswith(('.txt', '.text')):
#             log.info(f"ğŸ“ Processing text attachment: {filename}")
#             with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
#                 txt = f.read()
#             txt_items = extract_items_from_text(txt)
#             items.extend(txt_items)
#             log.info(f"ğŸ“¦ TXT found {len(txt_items)} items")

#         # --- EXCEL FILE PROCESSING ---

#         elif filename.lower().endswith(('.xlsx', '.xls')):
#             log.info(f"ğŸ“ˆ Processing Excel attachment: {filename}")
#             try:
#                 import openpyxl
#                 workbook = openpyxl.load_workbook(file_path, read_only=True, data_only=True)
#                 sheet = workbook.active
#                 excel_items = []
#                 for row in sheet.iter_rows(values_only=True):
#                     row_text = ' '.join(str(cell) for cell in row if cell is not None)
#                     if row_text.strip():
#                         row_items = extract_items_from_text(row_text)
#                         excel_items.extend(row_items)
#                 items.extend(excel_items)
#                 log.info(f"ğŸ“¦ Excel found {len(excel_items)} items")
#                 workbook.close()
#             except Exception as e:
#                 log.warning(f"Excel processing error: {e}")
#                 try:
#                     with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
#                         txt = f.read()
#                     fallback_items = extract_items_from_text(txt)
#                     items.extend(fallback_items)
#                     log.info(f"ğŸ“¦ Excel fallback found {len(fallback_items)} items")
#                 except Exception as fallback_error:
#                     log.error(f"Excel fallback also failed: {fallback_error}")

#         # --- OTHER FILE TYPES ---

#         else:
#             log.info(f"ğŸ” Processing other file type: {filename}")
#             try:
#                 with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
#                     txt = f.read()
#                 other_items = extract_items_from_text(txt)
#                 items.extend(other_items)
#                 log.info(f"ğŸ“¦ Other file type found {len(other_items)} items")
#             except Exception:
#                 log.info(f"âŒ Skipping unknown/binary attachment type: {filename}")

#         log.info(f"ğŸ“¦ Total items extracted from attachment: {len(items)}")
#         return items

#     except Exception as e:
#         log.error(f"âŒ Attachment processing error ({file_path}): {e}", exc_info=True)
#         return []
    
# def correct_ocr_code(ocr_code: str, known_parts: list):
#     if not ocr_code:
#         return ocr_code
#     code = str(ocr_code).strip().upper()

   
#     if len(code) < 4:
#         return code

#     original = code

#     pattern_corrections = [
#         (" ", ""),        
#         ("O", "0"),       
#         ("I", "1"),      
#         ("L", "1"),       
#         ("B1JTD", "B1JTTD"),
#     ]
#     for wrong, right in pattern_corrections:
#         if wrong in code:
#             code = code.replace(wrong, right)

   
#     try:
#         if known_parts:
#             match = get_close_matches(code, known_parts, n=1, cutoff=0.82)
#             if match:
#                 corrected = match[0].strip().upper()
#                 if corrected != original:
#                     log.info(f"[OCR Correction] '{original}' â†’ '{corrected}' (fuzzy match)")
#                 return corrected
#     except Exception as e:
#         log.debug(f"OCR fuzzy match error: {e}")

#     if code != original:
#         log.info(f"[OCR Correction] '{original}' â†’ '{code}' (pattern fix)")
#     return code





# # for uploading file

# def process_uploaded_file_for_items(filepath: str):
    
#     filename = os.path.basename(filepath)
#     items = []
#     try:
#         if filename.lower().endswith('.pdf'):
#             with open(filepath, 'rb') as f:
#                 pdf_bytes = f.read()
#             ocr_text = ocr_pdf_with_openai(pdf_bytes)
#             log.debug(f"OCR raw output for uploaded file: {repr(ocr_text)}")

#             for line in (ocr_text or "").splitlines():
#                 line = line.strip()
#                 if not line:
#                     continue
#                 m = re.match(r'^["\']?([^\n,]+?)["\']?\s*[,ï¼Œ]\s*(\d+)', line)
#                 if m:
#                     part_num = m.group(1).strip()
#                     qty = int(m.group(2))
#                     items.append({"hcod": part_num, "qty": qty})
#                 else:
#                     token = line.strip().strip('"').strip("'")
#                     if token:
#                         items.append({"hcod": token, "qty": 1})

#         elif filename.lower().endswith('.csv'):
#             with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
#                 sample = f.read(2048)
#                 f.seek(0)
#                 try:
#                     delimiter = csv.Sniffer().sniff(sample).delimiter
#                 except Exception:
#                     delimiter = ','
#                 reader = csv.DictReader(f, delimiter=delimiter)
#                 for row in reader:
#                     row_lower = { (k or "").strip().lower(): (v or "").strip() for k, v in row.items() if k is not None }
                    
                    
#                     qty_val = row_lower.get('qty') or row_lower.get('quantity') or row_lower.get('æ•°é‡') or row_lower.get('q') or '1'
#                     try:
#                         qty = int(float(qty_val))
#                     except:
#                         qty = 1

                    
#                     part_val = row_lower.get('hcod') or row_lower.get('å“ç•ª') or row_lower.get('hnm') or \
#                                row_lower.get('part number') or row_lower.get('mpn') or None
#                     if part_val and str(part_val).strip():
#                         items.append({"hcod": str(part_val).strip().strip('"').strip("'"), "qty": qty})
#                     else:
#                         # fallback: first non-qty field
#                         for k, v in row_lower.items():
#                             if k in ['qty', 'quantity', 'æ•°é‡', 'q', '']:
#                                 continue
#                             if v and v.strip():
#                                 items.append({"hcod": v.strip().strip('"').strip("'"), "qty": qty})
#                                 break

#         elif filename.lower().endswith(('.txt', '.text')):
#             with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
#                 txt = f.read()
#             extracted_items = extract_items_from_text(txt)
           
#             for hcod, qty in extracted_items:
#                 items.append({"hcod": hcod, "qty": qty})

#         else:
           
#             with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
#                 txt = f.read()
#             extracted_items = extract_items_from_text(txt)
#             for hcod, qty in extracted_items:
#                 items.append({"hcod": hcod, "qty": qty})

#     except Exception as e:
#         log.warning(f"Attachment error ({filename}): {e}", exc_info=True)

#     return items








# backend/utils/ocr_utils.py
import tempfile
import base64
import os
import re
import logging
from pdf2image import convert_from_bytes
from config import Config
from openai import OpenAI
from difflib import get_close_matches
import csv

# Optional: pdfplumber for structured parsing
try:
    import pdfplumber
    from io import BytesIO
    PDFPLUMBER_AVAILABLE = True
except ImportError:
    PDFPLUMBER_AVAILABLE = False
    logging.getLogger(__name__).warning("pdfplumber not installed. Falling back to AI OCR.")

client = OpenAI(api_key=Config.OPENAI_API_KEY) if getattr(Config, "OPENAI_API_KEY", None) else None

log = logging.getLogger(__name__)


def normalize_text(text: str) -> str:
    if not text:
        return ""
    text = re.sub(r'[ï¼-ï¼™]', lambda m: str(ord(m.group()) - 0xFEE0), text)
    return re.sub(r'\s+', ' ', text.strip())


def extract_items_from_text(text: str):
    """Fallback for non-PDF or unstructured files."""
    if not text:
        return []
    text = normalize_text(text)
    items = []

    hcod_pattern = re.compile(
        r'H\s*(\d{6})\s*(?:[:ï¼š\-\s]*[xÃ—*]?\s*(?:qty|æ•°é‡|å€‹|pcs|pc|ea|æœ¬|æš|ã‚»ãƒƒãƒˆ|units?)?\s*[:ï¼š]?\s*)?(\d+)',
        re.IGNORECASE
    )
    for m in hcod_pattern.finditer(text):
        code = f"H{m.group(1)}"
        qty = int(m.group(2))
        items.append((code, qty))

    all_hcods = re.findall(r'H\s*(\d{6})', text, re.IGNORECASE)
    existing = {code for code, _ in items}
    for digits in all_hcods:
        code = f"H{digits}"
        if code not in existing:
            items.append((code, 1))

    lines = re.split(r'[\n\r]+', text)
    for line in lines:
        line = line.strip()
        if not line:
            continue
        part_qty = re.search(
            r'([\w\s\-â€“â€•/ï¼\(\)\[\]\u3000-\u9FFFÎ©Î¼a-zA-Z0-9\.\+\=\&]{2,80}?)'
            r'\s*[xÃ—ï¼Š*]\s*'
            r'(\d{1,5})'
            r'(?:\s*(?:pcs|å€‹|æœ¬|æš|ã‚»ãƒƒãƒˆ|pc|ea|units?|ç‚¹))?\b',
            line,
            re.IGNORECASE
        )
        if part_qty:
            name = part_qty.group(1).strip()
            qty = int(part_qty.group(2))
            name = re.sub(r'[,\.\-_:\s;ã€ã€‚]+$', '', name)
            if len(name) >= 2:
                items.append((name, qty))
            continue
        fallback = re.search(
            r'([\w\s\-â€“â€•/ï¼\(\)\[\]\u3000-\u9FFFÎ©Î¼a-zA-Z0-9\.\+\=\&]{2,80}?)\s+(\d{1,4})\s*$',
            line,
            re.IGNORECASE
        )
        if fallback:
            name = fallback.group(1).strip()
            qty = int(fallback.group(2))
            name = re.sub(r'[,\.\-_:\s;ã€ã€‚]+$', '', name)
            if len(name) >= 2:
                items.append((name, qty))
    return items


def extract_items_from_structured_po(pdf_bytes: bytes):
    """
    Handles both:
    - Tokyo Tron (paired rows, lined table)
    - Futami Denki (simple borderless table)
    """
    if not PDFPLUMBER_AVAILABLE:
        return None

    items = []
    try:
        with pdfplumber.open(BytesIO(pdf_bytes)) as pdf:
            for page in pdf.pages:
                # Try line-based first (Tokyo Tron)
                table = page.extract_table({
                    "vertical_strategy": "lines",
                    "horizontal_strategy": "lines"
                })

                # If too few rows, try text-based (Futami Denki)
                if not table or len(table) <= 3:
                    table = page.extract_table({
                        "vertical_strategy": "text",
                        "horizontal_strategy": "text",
                        "min_words_vertical": 2,
                        "min_words_horizontal": 2
                    })

                if not table or len(table) < 2:
                    continue

                # Detect table type by checking for paired structure
                is_paired = False
                for i in range(1, min(5, len(table))):
                    row = table[i]
                    if row and len(row) >= 2:
                        cell = (row[1] or "").strip()
                        if re.match(r'^(9KJ|TD0-|TE0-|EC\d{8})', cell):
                            is_paired = True
                            break

                if is_paired:
                    # Tokyo Tron style: paired rows
                    rows = table[2:] if len(table) > 2 else table
                    i = 0
                    while i < len(rows) - 1:
                        row_a = rows[i]      # internal code row (has quantity)
                        row_b = rows[i + 1]  # real part row

                        if len(row_a) >= 5 and len(row_b) >= 2:
                            qty_field = (row_a[4] or "").strip()
                            qty_str = qty_field.split('\n')[0].replace(',', '').strip()
                            qty = int(qty_str) if qty_str.isdigit() else 1

                            part_name = (row_b[1] or "").strip()
                            if part_name and re.match(r'^[A-Za-z0-9/\.\-_]{5,}$', part_name):
                                if not re.match(r'^(9KJ|TD0-|TE0-|EC\d{8})', part_name):
                                    items.append((part_name, qty))
                        i += 2
                else:
                    # Futami Denki style: simple table
                    for row in table[1:]:
                        if not row or len(row) < 4:
                            continue
                        part_name = None
                        qty = 1

                        # Find part number (alphanum + dash, e.g., 36110-3000FD)
                        for cell in row:
                            cell = (cell or "").strip()
                            if re.match(r'^[A-Za-z0-9\-]{6,}$', cell):
                                part_name = cell
                                break

                        # Find quantity (small integer)
                        for cell in row:
                            cell = (cell or "").strip()
                            if cell.isdigit() and 1 <= int(cell) <= 99999:
                                qty = int(cell)
                                break

                        if part_name:
                            items.append((part_name, qty))

        log.info(f"âœ… Extracted {len(items)} items from PDF")
        return items

    except Exception as e:
        log.warning(f"Structured parsing failed: {e}", exc_info=True)
        return None


def ocr_pdf_with_openai(pdf_bytes: bytes) -> str:
    """Fallback OCR using GPT-4o Vision."""
    if not client:
        log.warning("OpenAI client not configured; skipping OCR.")
        return ""

    try:
        log.info("ğŸ”„ Converting PDF to image for fallback OCR...")
        images = convert_from_bytes(pdf_bytes, first_page=1, last_page=3)
        if not images:
            return ""

        all_ocr_text = ""
        for page_num, image in enumerate(images, 1):
            img_path = os.path.join(tempfile.gettempdir(), f"temp_ocr_page_{page_num}.jpg")
            try:
                image.save(img_path, format="JPEG", quality=85)
                with open(img_path, "rb") as f:
                    encoded_img = base64.b64encode(f.read()).decode('utf-8')
                image_data_url = f"data:image/jpeg;base64,{encoded_img}"

                prompt = (
                    "ä»¥ä¸‹ã®æ³¨æ–‡æ›¸ç”»åƒã‹ã‚‰ã€æœ‰åŠ¹ãªã€Œéƒ¨å“è­˜åˆ¥å­ã€ã¨ã€Œæ•°é‡ã€ã®ã¿ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚\n"
                    "ã€æœ‰åŠ¹ãªéƒ¨å“è­˜åˆ¥å­ã¨ã¯ã€‘\n"
                    "- ãƒ¡ãƒ¼ã‚«å“ç•ªï¼ˆä¾‹: RK73Z1ETTP, CF1/4CS100J, 36110-3000FDï¼‰\n"
                    "- Hã‚³ãƒ¼ãƒ‰ï¼ˆä¾‹: H123456ï¼‰\n"
                    "- å“ç•ªã¯è‹±æ•°å­—ã¨è¨˜å·ï¼ˆ/, -, .ï¼‰ã‚’å«ã¿ã€é€šå¸¸5æ–‡å­—ä»¥ä¸Š\n"
                    "ã€çµ¶å¯¾ã«æŠ½å‡ºã—ãªã„ã‚‚ã®ã€‘\n"
                    "- å†…éƒ¨ç®¡ç†ã‚³ãƒ¼ãƒ‰ï¼ˆä¾‹: EC00384035, 9KJ11105000, TD0-14524001ï¼‰\n"
                    "- æ—¥æœ¬èªå“åã®ã¿ï¼ˆä¾‹: æŠµæŠ—å™¨ï¼‰\n"
                    "- é‡‘é¡ã€ç´æœŸã€ç¨åŒºåˆ†ã€å‚™è€ƒã€ãƒ˜ãƒƒãƒ€ã€ãƒ•ãƒƒã‚¿ã€åˆè¨ˆè¡Œ\n"
                    "ã€æ•°é‡ãƒ«ãƒ¼ãƒ«ã€‘\n"
                    "- æ•°é‡ã¯å¯¾å¿œã™ã‚‹ã€Œæ•°é‡ã€æ¬„ã®æ•°å€¤\n"
                    "- ä¸æ˜ãªå ´åˆã¯ã€Œ1ã€\n"
                    "ã€å‡ºåŠ›å½¢å¼ã€‘\n"
                    "- 1è¡Œã«ã¤ãã€Œéƒ¨å“è­˜åˆ¥å­,æ•°é‡ã€ï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šï¼‰\n"
                    "- ä¾‹: RK73Z1ETTP,100\n"
                    "- ç´”ç²‹ãªãƒ†ã‚­ã‚¹ãƒˆã®ã¿å‡ºåŠ›"
                )

                response = client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=[{
                        "role": "user",
                        "content": [
                            {"type": "text", "text": prompt},
                            {"type": "image_url", "image_url": {"url": image_data_url}}
                        ]
                    }],
                    max_tokens=1500,
                    temperature=0.1
                )
                page_text = getattr(response.choices[0].message, 'content', "") or ""
                if page_text:
                    all_ocr_text += page_text + "\n"
            except Exception as e:
                log.error(f"Page {page_num} OCR error: {e}", exc_info=True)
            finally:
                try:
                    os.remove(img_path)
                except:
                    pass
        return all_ocr_text.strip()

    except Exception as e:
        log.error(f"OCR fallback failed: {e}", exc_info=True)
        return ""


def extract_items_from_attachment(file_path):
    if not isinstance(file_path, str) or not os.path.isfile(file_path):
        log.warning("Invalid file path")
        return []

    items = []
    filename = os.path.basename(file_path)
    log.info(f"ğŸ“ Processing: {filename}")

    try:
        if filename.lower().endswith('.pdf'):
            log.info("ğŸ“„ Parsing PDF with hybrid method")
            with open(file_path, 'rb') as f:
                pdf_bytes = f.read()

            items = extract_items_from_structured_po(pdf_bytes) if PDFPLUMBER_AVAILABLE else None
            if not items:
                log.info("ğŸ”„ Falling back to GPT-4o Vision OCR")
                ocr_text = ocr_pdf_with_openai(pdf_bytes)
                if ocr_text:
                    for line in ocr_text.splitlines():
                        line = line.strip()
                        if not line:
                            continue
                        m = re.match(r'^["\']?([^,\n]+?)["\']?\s*[,ï¼Œ]\s*(\d+)', line)
                        if m:
                            items.append((m.group(1).strip(), int(m.group(2))))
                        else:
                            items.append((line, 1))
            log.info(f"ğŸ“¦ Extracted {len(items)} items")
            return items

        # --- Other file types (unchanged) ---
        elif filename.lower().endswith('.csv'):
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                sample = f.read(2048)
                f.seek(0)
                try:
                    delimiter = csv.Sniffer().sniff(sample).delimiter
                except:
                    delimiter = ','
                reader = csv.DictReader(f, delimiter=delimiter)
                for row in reader:
                    row_lower = { (k or "").strip().lower(): (v or "").strip() for k, v in row.items() if k is not None }
                    qty_val = row_lower.get('qty') or row_lower.get('quantity') or row_lower.get('æ•°é‡') or row_lower.get('å€‹æ•°') or row_lower.get('q') or '1'
                    qty = int(float(qty_val)) if qty_val.replace('.', '').isdigit() else 1
                    part_val = row_lower.get('hcod') or row_lower.get('å“ç•ª') or row_lower.get('hnm') or row_lower.get('part number') or row_lower.get('mpn') or None
                    if part_val and str(part_val).strip():
                        items.append((str(part_val).strip().strip('"').strip("'"), qty))
                    else:
                        for k, v in row_lower.items():
                            if k in ['qty', 'quantity', 'æ•°é‡', 'å€‹æ•°', 'q', '']:
                                continue
                            if v and v.strip():
                                items.append((v.strip().strip('"').strip("'"), qty))
                                break

        elif filename.lower().endswith(('.txt', '.text')):
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                txt = f.read()
            items = extract_items_from_text(txt)

        elif filename.lower().endswith(('.xlsx', '.xls')):
            try:
                import openpyxl
                workbook = openpyxl.load_workbook(file_path, read_only=True, data_only=True)
                sheet = workbook.active
                for row in sheet.iter_rows(values_only=True):
                    row_text = ' '.join(str(cell) for cell in row if cell is not None)
                    if row_text.strip():
                        items.extend(extract_items_from_text(row_text))
                workbook.close()
            except Exception as e:
                log.warning(f"Excel error: {e}")
                try:
                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                        txt = f.read()
                    items = extract_items_from_text(txt)
                except:
                    pass

        else:
            try:
                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    txt = f.read()
                items = extract_items_from_text(txt)
            except:
                log.info(f"Skipping binary file: {filename}")

        log.info(f"ğŸ“¦ Total items: {len(items)}")
        return items

    except Exception as e:
        log.error(f"Attachment error: {e}", exc_info=True)
        return []


def correct_ocr_code(ocr_code: str, known_parts: list):
    if not ocr_code:
        return ocr_code
    code = str(ocr_code).strip().upper()
    if len(code) < 4:
        return code

    original = code
    pattern_corrections = [(" ", ""), ("O", "0"), ("I", "1"), ("L", "1"), ("B1JTD", "B1JTTD")]
    for wrong, right in pattern_corrections:
        code = code.replace(wrong, right)

    try:
        if known_parts:
            match = get_close_matches(code, known_parts, n=1, cutoff=0.82)
            if match:
                corrected = match[0].strip().upper()
                if corrected != original:
                    log.info(f"[OCR Correction] '{original}' â†’ '{corrected}'")
                return corrected
    except Exception as e:
        log.debug(f"Fuzzy match error: {e}")

    if code != original:
        log.info(f"[OCR Correction] '{original}' â†’ '{code}'")
    return code


def process_uploaded_file_for_items(filepath: str):
    filename = os.path.basename(filepath)
    items = []
    try:
        if filename.lower().endswith('.pdf'):
            with open(filepath, 'rb') as f:
                pdf_bytes = f.read()
            structured_items = extract_items_from_structured_po(pdf_bytes) if PDFPLUMBER_AVAILABLE else None
            if structured_items:
                for part, qty in structured_items:
                    items.append({"hcod": part, "qty": qty})
            else:
                ocr_text = ocr_pdf_with_openai(pdf_bytes)
                for line in (ocr_text or "").splitlines():
                    line = line.strip()
                    if not line:
                        continue
                    m = re.match(r'^["\']?([^\n,]+?)["\']?\s*[,ï¼Œ]\s*(\d+)', line)
                    if m:
                        items.append({"hcod": m.group(1).strip(), "qty": int(m.group(2))})
                    else:
                        items.append({"hcod": line, "qty": 1})
        else:
            raw_items = extract_items_from_attachment(filepath)
            for part, qty in raw_items:
                items.append({"hcod": part, "qty": qty})
    except Exception as e:
        log.warning(f"File processing error: {e}", exc_info=True)
    return items